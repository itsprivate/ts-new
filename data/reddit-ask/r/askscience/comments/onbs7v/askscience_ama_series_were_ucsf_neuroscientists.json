{
  "author": "AskScienceModerator",
  "original_created_utc": 1626692440,
  "title": "AskScience AMA Series: We're UCSF neuroscientists who were featured in the NY Times for developing a neuroprosthesis that enabled a man with severe paralysis to communicate in full sentences simply by attempting to speak. AUA!",
  "created_utc": 1626764495,
  "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Hi Reddit! We&#39;re a team of neuroscientists at the University of California, San Francisco (aka UCSF). We just published results from our work on technology that translates signals from the brain region that normally controls the muscles of the vocal tract directly into full words and sentences. To our knowledge, this is the first demonstration to show that intended messages can be decoded from speech-related brain activity in a person who is paralyzed and unable to speak naturally. This new paper is the culmination of more than a decade of research in the lab led by UCSF neurosurgeon Edward Chang, MD.</p>\n\n<p>Off the bat, we want to clarify one common misconception about our work: We are not able to &quot;read minds&quot; and this is not our goal! Our technology detects signals aimed at the muscles that make speech happen, meaning that we&#39;re capturing intentional attempts at outward speech, not general thoughts or the &quot;inner voice&quot;. Our entire motivation is to help restore independence and the ability to speak to people who can&#39;t communicate using assistive methods.</p>\n\n<p>Our work differs from previous neuroprostheses in a critical way: Other studies have focused on restoring communication through spelling-based approaches, typing out letters one-by-one. Our team is translating signals intended to control muscles of the vocal system for speaking words, rather than signals to move the arm or hand to enable typing or control of a computer cursor.</p>\n\n<p>Also, we want to note that this is very early work conducted with a single person as a proof of concept. This study participant &quot;Bravo-1&quot;, to whom we&#39;re extremely grateful, is a man in his late 30s who suffered a devastating brainstem stroke that severely damaged the connection between his brain and his vocal tract and limbs. Because he is unable to speak naturally or move his hands to type, to communicate he typically uses assistive technology controlled by minute and effortful head movements.</p>\n\n<p>To summarize the approach used in this study, we surgically implanted a high-density electrode array over his speech motor cortex (the part of the brain that normally controls the vocal tract). We then used machine learning to model complex patterns in his brain activity as he tried to say 50 common words. Afterwards, we used these models and a natural-language model to translate his brain activity into the words and sentences he attempted to say.</p>\n\n<p>Ultimately, we hope this type of neurotechnology can make communication faster and more natural for those who are otherwise unable to speak due to stroke, neurodegenerative disease (such as ALS), or traumatic brain injury. But we&#39;ve got a lot of work to do before something like this is available to patients at large.</p>\n\n<ul>\n<li><a href=\"http://tiny.ucsf.edu/zcNuQr\">Here&#39;s a UCSF press release about the study and how the technology works, including an animation of the setup of the trial.</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=_GMcf1fXdW8\">Here&#39;s a video on our study from UCSF.</a></li>\n<li><a href=\"https://www.nejm.org/doi/full/10.1056/NEJMoa2027540\">Here&#39;s a direct link to the study published in the New England Journal of Medicine</a></li>\n</ul>\n\n<p>We&#39;re here to answer questions and, hopefully, to raise awareness of communication neuroprosthetics as a field of study and means of improving the lives of people around the world.\nAnswering questions today are the co-lead authors of the new study:</p>\n\n<ul>\n<li>David A. Moses, Ph.D., postdoctoral engineer</li>\n<li>Sean L. Metzger, M.S., doctoral student</li>\n<li>Jessie R. Liu, B.S., doctoral student</li>\n</ul>\n\n<p>Hi, Reddit! We’re online and excited to answer your questions.</p>\n</div><!-- SC_ON -->",
  "score": 101,
  "permalink": "/r/askscience/comments/onbs7v/askscience_ama_series_were_ucsf_neuroscientists/",
  "subreddit": "askscience",
  "id": "onbs7v",
  "is_self": true,
  "media": null,
  "is_video": false,
  "the_new_excerpt": "Hi Reddit! We're a team of neuroscientists at the University of California, San\nFrancisco (aka UCSF). We just published results from our work on technology that\ntranslates signals from the brain region that normally controls the muscles of\nthe vocal tract directly into full words and sentences. To…",
  "localize": [
    {
      "locale": "ja",
      "the_new_excerpt": "こんにちは、Reddit! 私たちは、カリフォルニア大学サンフランシスコ校（通称UCSF）の神経科学者のチームです。\nフランシスコ（通称UCSF）の神経科学者チームです。私たちは、以下のような技術の研究成果を発表しました。\n声道の筋肉をコントロールする脳領域からの信号を\n声道の筋肉を制御する脳領域からの信号を、完全な単語や文章に直接変換する技術に関する研究結果を発表しました。この技術は...",
      "title": "AskScience AMAシリーズ。私たちは、重度の麻痺を持つ男性が話そうとするだけでフルセンテンスでのコミュニケーションを可能にする神経人工器官を開発したことで、NY Timesに取り上げられたUCSFの神経科学者です。AUA!"
    },
    {
      "locale": "zh",
      "the_new_excerpt": "嗨，Reddit! 我们是加州大学旧金山分校（又称加州大学旧金山分校）的一个神经科学家团队。\n旧金山大学（又名UCSF）的一个神经科学家团队。我们刚刚发表了我们在技术方面的成果，即\n将来自通常控制声带肌肉的大脑区域的信号直接翻译成完整的声带。\n将通常控制声道肌肉的大脑区域的信号直接转化为完整的单词和句子。为了...",
      "title": "AskScience AMA系列。我们是加州大学旧金山分校的神经科学家，他们开发了一种神经假体，使一个严重瘫痪的人只需尝试说话就能用完整的句子交流，因此被纽约时报报道。AUA!"
    },
    {
      "locale": "zh-Hant",
      "the_new_excerpt": "嗨，Reddit! 我們是加州大學舊金山分校（又稱加州大學舊金山分校）的一個神經科學家團隊。\n舊金山大學（又名UCSF）的一個神經科學家團隊。我們剛剛發表了我們在技術方面的成果，即\n將來自通常控制聲帶肌肉的大腦區域的信號直接翻譯成完整的聲帶。\n將通常控制聲道肌肉的大腦區域的信號直接轉化爲完整的單詞和句子。爲了...",
      "title": "AskScience AMA系列。我們是加州大學舊金山分校的神經科學家，他們開發了一種神經假體，使一個嚴重癱瘓的人只需嘗試說話就能用完整的句子交流，因此被紐約時報報道。AUA!"
    }
  ]
}