{
  "author": "TheIndulgery",
  "the_new_excerpt": "Just like everyone else I want to find a way to use these Reddit scrapers to\nactually make some money. Since I'm a data nerd I track any that I can and\nanalyze their hit rate, profitability, etc. I was using Unbias very successfully\nand making good money until it stopped updating (see original post…",
  "original_created_utc": 1623699692,
  "localize": [
    {
      "locale": "ja",
      "the_new_excerpt": "他の人と同じように、私もこのRedditスクレイパーを使って実際にお金を稼ぐ方法を見つけたいと思っています。\n実際にお金を稼ぐ方法を探しています。私はデータオタクなので、できる限りトラッキングして\nヒット率や収益性などを分析しています。私はUnbiasを非常にうまく使っていました。\n順調に稼いでいたのですが、更新が止まってしまいました（元記事参照）。",
      "title": "3つのRedditスクレイパーの値を30日間追跡する"
    },
    {
      "locale": "zh",
      "the_new_excerpt": "就像其他人一样，我想找到一种方法，利用这些Reddit刮刀来\n真正赚到一些钱。因为我是一个数据呆子，所以我追踪任何我可以追踪的东西，并\n分析他们的点击率、盈利能力等。我曾非常成功地使用Unbias\n赚了不少钱，直到它停止更新（见原帖...",
      "title": "追踪3个Reddit搜刮器的价值，为期30天"
    },
    {
      "locale": "zh-Hant",
      "the_new_excerpt": "就像其他人一樣，我想找到一種方法，利用這些Reddit刮刀來\n真正賺到一些錢。因爲我是一個數據呆子，所以我追蹤任何我可以追蹤的東西，並\n分析他們的點擊率、盈利能力等。我曾非常成功地使用Unbias\n賺了不少錢，直到它停止更新（見原帖...",
      "title": "追蹤3個Reddit搜刮器的價值，爲期30天"
    }
  ],
  "title": "Tracking the value of 3 Reddit scrapers for 30 days",
  "created_utc": 1623705800,
  "selftext_html": "<!-- SC_OFF --><div class=\"md\"><p>Just like everyone else I want to find a way to use these Reddit scrapers to actually make some money. Since I&#39;m a data nerd I track any that I can and analyze their hit rate, profitability, etc. I was using Unbias very successfully and making good money until it stopped updating (<a href=\"https://www.reddit.com/r/stocks/comments/m71xi8/a_month_of_tracking_stock_scrapers_for/\">see original post here</a>)</p>\n\n<p>&#x200B;</p>\n\n<p>Since then I have been tracking 3 scrapers and 1 methodology I saw here:</p>\n\n<ul>\n<li><a href=\"https://www.reddit.com/r/MillennialBets/wiki/index/user/theindulgery\">Millenial Bets</a></li>\n<li><a href=\"https://hype-rider.com/reddit\">Hype Rider</a></li>\n<li><a href=\"https://dayminer.herokuapp.com/\">Dayminer</a></li>\n<li><a href=\"https://docs.google.com/spreadsheets/d/1wBbawSwzpei5Q93Erg26Ii8JADFryoM2smpNTx5F9aM/edit#gid=910606400\">Using Finviz to see if buying the biggest losers of the day and selling the next morning for a 1% profit would work</a></li>\n</ul>\n\n<p>&#x200B;</p>\n\n<p><strong>Fair warning:</strong> Google Sheets struggles with large amounts of data and a lot of people logging in, so I created multiples of each spreadsheet. If you have trouble getting in all I can recommend is continuing to try. If you do, make a copy for yourself.</p>\n\n<p>&#x200B;</p>\n\n<p><strong>Summaries:</strong></p>\n\n<ul>\n<li><strong>Easiest to gather data: Millenial Bets</strong>. This is a straight copy/paste. The others required a lot of Excel copy, pasting, sorting, etc to get it to fit into the sheets</li>\n<li><strong>Best average returns: Millenial Bets.</strong> This may be because they had the biggest quantity of results. It&#39;s hard to narrow this down to just a few tickers to buy, so looks good as a paper trader but hard to put into use in the real world</li>\n<li><strong>Best at returning a small list of tickers to buy: Dayminer.</strong> This data narrows down to just a few, or sometimes none, per day. But the ones that do hit tend to hit pretty consistently</li>\n</ul>\n\n<p>&#x200B;</p>\n\n<p><strong>End Results from tracking the data:</strong> <em>(When paper trading I chose categories that had a % of Profitable vs Non-Profitable returns of greater than 90%. I was aiming for highest success rate of being profitable)</em></p>\n\n<ul>\n<li><p><strong>Millenial Bets:</strong> </p>\n\n<ul>\n<li><strong>Total data points:</strong> 5573</li>\n<li><strong>Number of paper trades:</strong> 2212</li>\n<li><strong>% return (avg):</strong> 11.44%</li>\n<li><strong>% return (max):</strong> 50%</li>\n<li><strong># of days to max profit (avg):</strong> 6<br/></li>\n</ul></li>\n<li><p><strong>Hype Rider:</strong> </p>\n\n<ul>\n<li><strong>Total data points:</strong> 5425</li>\n<li><strong>Number of paper trades:</strong> 714</li>\n<li><strong>% return (avg):</strong> 7.03%</li>\n<li><strong>% return (max): 13.19</strong>%</li>\n<li><strong># of days to max profit (avg):</strong> 4<br/></li>\n</ul></li>\n<li><p><strong>Dayminer:</strong> </p>\n\n<ul>\n<li><strong>Total data points:</strong> 5111</li>\n<li><strong>Number of paper trades:</strong> 278</li>\n<li><strong>% return (avg):</strong> 8.67%</li>\n<li><strong>% return (max):</strong> 29.77%</li>\n<li><strong># of days to max profit (avg):</strong> 5</li>\n</ul></li>\n</ul>\n\n<p>&#x200B;</p>\n\n<p><strong>How do I use this data?</strong> This is the question I get asked the most often. Here&#39;s what I do:</p>\n\n<ol>\n<li>Every morning before market open I copy the data from the scrapers, do whatever post-processing I need to do to get it to fit into the sheets, then paste into the sheets. This captures all the sentiment data from the last 24 hours</li>\n<li>When I&#39;m ready to buy something I look at the highest profitability categories in the data crunching tabs</li>\n<li>From there I narrow down THAT DAY&#39;S list of tickers based on the highest profitability categories</li>\n<li>I&#39;ll do a quick search on Reddit to see if overall sentiment is bullish or bearish. If everyone looks hopeful I&#39;ll buy</li>\n<li>I look at the average % returns and the average number of days to get there and those are my exit points<br/></li>\n</ol>\n\n<p>&#x200B;</p>\n\n<p>Now, on to the good stuff. Here are the links:<br/>\n<strong>Millenial Bets:</strong> <a href=\"https://imgur.com/gallery/nn14i7y\">Screen shots of the tables</a> | <a href=\"https://docs.google.com/spreadsheets/d/1iWKdaMUSdQ5G5ZUHabL7z5YKR-ZZalLqCD1Yv8ougZI/edit?usp=sharing\">Data (1)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1wav7ZnQlk6NE1vMWFmx941fHzVMi_QFKlbtRRKsEaCY/edit?usp=sharing\">Data (2)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1PXKCzJbva1NMAajASGNpmeO6LBVUT2PjZME3sS8S7yU/edit?usp=sharing\">Data (3)</a></p>\n\n<p><strong>Hype Rider:</strong> <a href=\"https://imgur.com/gallery/swbVZji\">Screen shots of the tables</a> | <a href=\"https://docs.google.com/spreadsheets/d/1vLUQTkZPzF924btqTWJXVrgmkLLHK4oOf1F1d3cSGP4/edit?usp=sharing\">Data (1)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1GZUl3PeGSHMg8Hld4-9Z5COHWf_sjbI7q3AnwMZvwV4/edit?usp=sharing\">Data (2)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1u5_nv1PxAdCvBN-m3gPODICrQA32UVz_FLEpskLm0Dw/edit?usp=sharing\">Data (3)</a></p>\n\n<p><strong>Dayminer</strong>: <a href=\"https://imgur.com/gallery/xUwlPTu\">Screen shots of tables</a> | <a href=\"https://docs.google.com/spreadsheets/d/1rRMFuvhHfC1SwZzZa1Y0AevB7U3dGmOECoKjUN9So8o/edit?usp=sharing\">Data (1)</a> | <a href=\"https://docs.google.com/spreadsheets/d/11-c3JLGOlpNx1A4Of_AE5Xq3nmoUSRJVCM-FmhXiSes/edit?usp=sharing\">Data (2)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1ojmjOf0Xxzy0nppxCAhplw104f0btOzfGhbAHg5RRE4/edit?usp=sharing\">Data (3)</a></p>\n\n<p><strong>Finviz All Time Low data:</strong> <a href=\"https://imgur.com/gallery/UHnUUAU\">Screen shots of the tables</a> | <a href=\"https://docs.google.com/spreadsheets/d/1kQMqf6gMeRfaJgYUDPB2Mux7nXJX8KsH-J3bJaYF-Jw/edit?usp=sharing\">Data (1)</a>| <a href=\"https://docs.google.com/spreadsheets/d/1JnvE1ud8sdGstD28P8Y940icrajiifhOdxL0LyNVCQQ/edit?usp=sharing\">Data (2)</a> | <a href=\"https://docs.google.com/spreadsheets/d/1EdBUMWr36t0Ibq-Yjn-1OnXjLyeJ7-Tw6q0q_h043do/edit?usp=sharing\">Data (3)</a> (Nothing really clear came of this data so I didn&#39;t highlight it in the post)</p>\n</div><!-- SC_ON -->",
  "score": 202,
  "permalink": "/r/stocks/comments/nzv3b1/tracking_the_value_of_3_reddit_scrapers_for_30/",
  "subreddit": "stocks",
  "id": "nzv3b1",
  "is_self": true,
  "media": null,
  "is_video": false,
  "source_updated_at": 1624009743480
}